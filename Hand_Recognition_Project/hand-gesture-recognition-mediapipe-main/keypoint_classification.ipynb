{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 各パス指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'model/keypoint_classifier/keypoint.csv'\n",
    "model_save_path = 'model/keypoint_classifier/keypoint_classifier.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分類数設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dataset = np.loadtxt(dataset, delimiter=',', dtype='float32', usecols=list(range(1, (21 * 2) + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dataset = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, train_size=0.75, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input((21 * 2, )),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(20, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">860</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m860\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m210\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,103</span> (4.31 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,103\u001b[0m (4.31 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,103</span> (4.31 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,103\u001b[0m (4.31 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()  # tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルチェックポイントのコールバック\n",
    "#cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    #model_save_path, verbose=1, save_weights_only=False)\n",
    "# 早期打ち切り用コールバック\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルコンパイル\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.3991 - loss: 1.0587 - val_accuracy: 0.3387 - val_loss: 1.0178\n",
      "Epoch 2/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4427 - loss: 1.0347 - val_accuracy: 0.3581 - val_loss: 0.9961\n",
      "Epoch 3/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4281 - loss: 1.0228 - val_accuracy: 0.4645 - val_loss: 0.9717\n",
      "Epoch 4/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5012 - loss: 0.9778 - val_accuracy: 0.6839 - val_loss: 0.9410\n",
      "Epoch 5/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5107 - loss: 0.9661 - val_accuracy: 0.7323 - val_loss: 0.8970\n",
      "Epoch 6/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5123 - loss: 0.9409 - val_accuracy: 0.7484 - val_loss: 0.8525\n",
      "Epoch 7/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5374 - loss: 0.9226 - val_accuracy: 0.7742 - val_loss: 0.8166\n",
      "Epoch 8/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5475 - loss: 0.9033 - val_accuracy: 0.8097 - val_loss: 0.7853\n",
      "Epoch 9/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5383 - loss: 0.8800 - val_accuracy: 0.8097 - val_loss: 0.7558\n",
      "Epoch 10/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5886 - loss: 0.8418 - val_accuracy: 0.8323 - val_loss: 0.7240\n",
      "Epoch 11/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6119 - loss: 0.8405 - val_accuracy: 0.8516 - val_loss: 0.6902\n",
      "Epoch 12/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6550 - loss: 0.8015 - val_accuracy: 0.8581 - val_loss: 0.6564\n",
      "Epoch 13/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6790 - loss: 0.7802 - val_accuracy: 0.8742 - val_loss: 0.6246\n",
      "Epoch 14/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6852 - loss: 0.7498 - val_accuracy: 0.8742 - val_loss: 0.5944\n",
      "Epoch 15/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6997 - loss: 0.7368 - val_accuracy: 0.8806 - val_loss: 0.5690\n",
      "Epoch 16/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7134 - loss: 0.7099 - val_accuracy: 0.8839 - val_loss: 0.5425\n",
      "Epoch 17/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7095 - loss: 0.6995 - val_accuracy: 0.8839 - val_loss: 0.5171\n",
      "Epoch 18/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7299 - loss: 0.6770 - val_accuracy: 0.8871 - val_loss: 0.4929\n",
      "Epoch 19/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7469 - loss: 0.6509 - val_accuracy: 0.8968 - val_loss: 0.4697\n",
      "Epoch 20/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7717 - loss: 0.6163 - val_accuracy: 0.8968 - val_loss: 0.4478\n",
      "Epoch 21/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7677 - loss: 0.6112 - val_accuracy: 0.9000 - val_loss: 0.4253\n",
      "Epoch 22/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7849 - loss: 0.5845 - val_accuracy: 0.8935 - val_loss: 0.4068\n",
      "Epoch 23/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7801 - loss: 0.5654 - val_accuracy: 0.8968 - val_loss: 0.3906\n",
      "Epoch 24/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7949 - loss: 0.5507 - val_accuracy: 0.9000 - val_loss: 0.3748\n",
      "Epoch 25/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8033 - loss: 0.5360 - val_accuracy: 0.9032 - val_loss: 0.3601\n",
      "Epoch 26/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7884 - loss: 0.5468 - val_accuracy: 0.8968 - val_loss: 0.3487\n",
      "Epoch 27/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7909 - loss: 0.5191 - val_accuracy: 0.8903 - val_loss: 0.3415\n",
      "Epoch 28/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8192 - loss: 0.4788 - val_accuracy: 0.8968 - val_loss: 0.3323\n",
      "Epoch 29/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7833 - loss: 0.5291 - val_accuracy: 0.8935 - val_loss: 0.3235\n",
      "Epoch 30/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8219 - loss: 0.4874 - val_accuracy: 0.8935 - val_loss: 0.3151\n",
      "Epoch 31/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8058 - loss: 0.5014 - val_accuracy: 0.8968 - val_loss: 0.3115\n",
      "Epoch 32/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8035 - loss: 0.4902 - val_accuracy: 0.9000 - val_loss: 0.3055\n",
      "Epoch 33/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8259 - loss: 0.4651 - val_accuracy: 0.9000 - val_loss: 0.3014\n",
      "Epoch 34/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8144 - loss: 0.4777 - val_accuracy: 0.9000 - val_loss: 0.2985\n",
      "Epoch 35/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8329 - loss: 0.4378 - val_accuracy: 0.8968 - val_loss: 0.2970\n",
      "Epoch 36/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8364 - loss: 0.4490 - val_accuracy: 0.8935 - val_loss: 0.2908\n",
      "Epoch 37/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8248 - loss: 0.4573 - val_accuracy: 0.8968 - val_loss: 0.2839\n",
      "Epoch 38/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8280 - loss: 0.4559 - val_accuracy: 0.9065 - val_loss: 0.2811\n",
      "Epoch 39/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8220 - loss: 0.4542 - val_accuracy: 0.8968 - val_loss: 0.2768\n",
      "Epoch 40/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8202 - loss: 0.4477 - val_accuracy: 0.8968 - val_loss: 0.2734\n",
      "Epoch 41/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8339 - loss: 0.4457 - val_accuracy: 0.9032 - val_loss: 0.2711\n",
      "Epoch 42/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8276 - loss: 0.4447 - val_accuracy: 0.9000 - val_loss: 0.2696\n",
      "Epoch 43/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8386 - loss: 0.4040 - val_accuracy: 0.8935 - val_loss: 0.2668\n",
      "Epoch 44/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8420 - loss: 0.4098 - val_accuracy: 0.8935 - val_loss: 0.2639\n",
      "Epoch 45/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8454 - loss: 0.4028 - val_accuracy: 0.8968 - val_loss: 0.2605\n",
      "Epoch 46/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8355 - loss: 0.4114 - val_accuracy: 0.8968 - val_loss: 0.2573\n",
      "Epoch 47/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8392 - loss: 0.4072 - val_accuracy: 0.9065 - val_loss: 0.2558\n",
      "Epoch 48/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8264 - loss: 0.4266 - val_accuracy: 0.9032 - val_loss: 0.2546\n",
      "Epoch 49/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8543 - loss: 0.3601 - val_accuracy: 0.9065 - val_loss: 0.2511\n",
      "Epoch 50/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8615 - loss: 0.4027 - val_accuracy: 0.9065 - val_loss: 0.2493\n",
      "Epoch 51/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8394 - loss: 0.4128 - val_accuracy: 0.9065 - val_loss: 0.2489\n",
      "Epoch 52/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8491 - loss: 0.4116 - val_accuracy: 0.9032 - val_loss: 0.2480\n",
      "Epoch 53/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8389 - loss: 0.4061 - val_accuracy: 0.9065 - val_loss: 0.2463\n",
      "Epoch 54/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8604 - loss: 0.3861 - val_accuracy: 0.9032 - val_loss: 0.2443\n",
      "Epoch 55/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8549 - loss: 0.4078 - val_accuracy: 0.9065 - val_loss: 0.2423\n",
      "Epoch 56/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8575 - loss: 0.3806 - val_accuracy: 0.9065 - val_loss: 0.2420\n",
      "Epoch 57/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8740 - loss: 0.3527 - val_accuracy: 0.9000 - val_loss: 0.2399\n",
      "Epoch 58/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8524 - loss: 0.3923 - val_accuracy: 0.9032 - val_loss: 0.2378\n",
      "Epoch 59/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8698 - loss: 0.3649 - val_accuracy: 0.9097 - val_loss: 0.2345\n",
      "Epoch 60/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8708 - loss: 0.3594 - val_accuracy: 0.9065 - val_loss: 0.2334\n",
      "Epoch 61/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8689 - loss: 0.3584 - val_accuracy: 0.9000 - val_loss: 0.2337\n",
      "Epoch 62/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8665 - loss: 0.3606 - val_accuracy: 0.9129 - val_loss: 0.2338\n",
      "Epoch 63/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8738 - loss: 0.3475 - val_accuracy: 0.9097 - val_loss: 0.2316\n",
      "Epoch 64/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8629 - loss: 0.3701 - val_accuracy: 0.9097 - val_loss: 0.2293\n",
      "Epoch 65/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8703 - loss: 0.3387 - val_accuracy: 0.9129 - val_loss: 0.2272\n",
      "Epoch 66/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8678 - loss: 0.3461 - val_accuracy: 0.9097 - val_loss: 0.2256\n",
      "Epoch 67/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8590 - loss: 0.3523 - val_accuracy: 0.9065 - val_loss: 0.2242\n",
      "Epoch 68/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8468 - loss: 0.3793 - val_accuracy: 0.9032 - val_loss: 0.2249\n",
      "Epoch 69/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8719 - loss: 0.3412 - val_accuracy: 0.9000 - val_loss: 0.2243\n",
      "Epoch 70/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8681 - loss: 0.3431 - val_accuracy: 0.9065 - val_loss: 0.2217\n",
      "Epoch 71/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8552 - loss: 0.3335 - val_accuracy: 0.9097 - val_loss: 0.2197\n",
      "Epoch 72/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8828 - loss: 0.3141 - val_accuracy: 0.9097 - val_loss: 0.2175\n",
      "Epoch 73/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8470 - loss: 0.4010 - val_accuracy: 0.9065 - val_loss: 0.2171\n",
      "Epoch 74/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8679 - loss: 0.3491 - val_accuracy: 0.9161 - val_loss: 0.2163\n",
      "Epoch 75/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8947 - loss: 0.3150 - val_accuracy: 0.9129 - val_loss: 0.2135\n",
      "Epoch 76/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8663 - loss: 0.3574 - val_accuracy: 0.9065 - val_loss: 0.2109\n",
      "Epoch 77/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8613 - loss: 0.3410 - val_accuracy: 0.9065 - val_loss: 0.2097\n",
      "Epoch 78/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8743 - loss: 0.3335 - val_accuracy: 0.9129 - val_loss: 0.2092\n",
      "Epoch 79/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8729 - loss: 0.3227 - val_accuracy: 0.9161 - val_loss: 0.2075\n",
      "Epoch 80/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8751 - loss: 0.3352 - val_accuracy: 0.9129 - val_loss: 0.2067\n",
      "Epoch 81/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8657 - loss: 0.3295 - val_accuracy: 0.9161 - val_loss: 0.2066\n",
      "Epoch 82/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8700 - loss: 0.3138 - val_accuracy: 0.9161 - val_loss: 0.2050\n",
      "Epoch 83/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8796 - loss: 0.3169 - val_accuracy: 0.9065 - val_loss: 0.2038\n",
      "Epoch 84/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8781 - loss: 0.3260 - val_accuracy: 0.9097 - val_loss: 0.2030\n",
      "Epoch 85/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8625 - loss: 0.3255 - val_accuracy: 0.9097 - val_loss: 0.2041\n",
      "Epoch 86/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8764 - loss: 0.3155 - val_accuracy: 0.9129 - val_loss: 0.2028\n",
      "Epoch 87/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8746 - loss: 0.3218 - val_accuracy: 0.9129 - val_loss: 0.1995\n",
      "Epoch 88/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8771 - loss: 0.3178 - val_accuracy: 0.9097 - val_loss: 0.1970\n",
      "Epoch 89/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9005 - loss: 0.3013 - val_accuracy: 0.9097 - val_loss: 0.1953\n",
      "Epoch 90/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8711 - loss: 0.3072 - val_accuracy: 0.9097 - val_loss: 0.1927\n",
      "Epoch 91/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8858 - loss: 0.3209 - val_accuracy: 0.9161 - val_loss: 0.1916\n",
      "Epoch 92/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8724 - loss: 0.2993 - val_accuracy: 0.9161 - val_loss: 0.1917\n",
      "Epoch 93/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8892 - loss: 0.3121 - val_accuracy: 0.9161 - val_loss: 0.1922\n",
      "Epoch 94/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8788 - loss: 0.3116 - val_accuracy: 0.9194 - val_loss: 0.1893\n",
      "Epoch 95/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8766 - loss: 0.3292 - val_accuracy: 0.9194 - val_loss: 0.1871\n",
      "Epoch 96/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8908 - loss: 0.3034 - val_accuracy: 0.9226 - val_loss: 0.1879\n",
      "Epoch 97/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8822 - loss: 0.3087 - val_accuracy: 0.9194 - val_loss: 0.1885\n",
      "Epoch 98/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8954 - loss: 0.2827 - val_accuracy: 0.9194 - val_loss: 0.1867\n",
      "Epoch 99/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8869 - loss: 0.3208 - val_accuracy: 0.9226 - val_loss: 0.1853\n",
      "Epoch 100/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8815 - loss: 0.3184 - val_accuracy: 0.9226 - val_loss: 0.1861\n",
      "Epoch 101/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8754 - loss: 0.3069 - val_accuracy: 0.9194 - val_loss: 0.1854\n",
      "Epoch 102/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9111 - loss: 0.2624 - val_accuracy: 0.9226 - val_loss: 0.1843\n",
      "Epoch 103/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9105 - loss: 0.2698 - val_accuracy: 0.9161 - val_loss: 0.1854\n",
      "Epoch 104/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8874 - loss: 0.3017 - val_accuracy: 0.9226 - val_loss: 0.1815\n",
      "Epoch 105/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8857 - loss: 0.3138 - val_accuracy: 0.9226 - val_loss: 0.1809\n",
      "Epoch 106/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9057 - loss: 0.2841 - val_accuracy: 0.9226 - val_loss: 0.1801\n",
      "Epoch 107/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8679 - loss: 0.3236 - val_accuracy: 0.9258 - val_loss: 0.1761\n",
      "Epoch 108/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8739 - loss: 0.3067 - val_accuracy: 0.9226 - val_loss: 0.1737\n",
      "Epoch 109/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9206 - loss: 0.2537 - val_accuracy: 0.9226 - val_loss: 0.1721\n",
      "Epoch 110/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8927 - loss: 0.2981 - val_accuracy: 0.9323 - val_loss: 0.1712\n",
      "Epoch 111/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8707 - loss: 0.3213 - val_accuracy: 0.9258 - val_loss: 0.1706\n",
      "Epoch 112/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8862 - loss: 0.2941 - val_accuracy: 0.9226 - val_loss: 0.1684\n",
      "Epoch 113/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8856 - loss: 0.2859 - val_accuracy: 0.9226 - val_loss: 0.1662\n",
      "Epoch 114/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8704 - loss: 0.3216 - val_accuracy: 0.9323 - val_loss: 0.1659\n",
      "Epoch 115/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8748 - loss: 0.2986 - val_accuracy: 0.9258 - val_loss: 0.1642\n",
      "Epoch 116/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9014 - loss: 0.2543 - val_accuracy: 0.9290 - val_loss: 0.1631\n",
      "Epoch 117/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8871 - loss: 0.2953 - val_accuracy: 0.9290 - val_loss: 0.1647\n",
      "Epoch 118/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8928 - loss: 0.2804 - val_accuracy: 0.9290 - val_loss: 0.1661\n",
      "Epoch 119/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8998 - loss: 0.2693 - val_accuracy: 0.9355 - val_loss: 0.1634\n",
      "Epoch 120/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8824 - loss: 0.2996 - val_accuracy: 0.9323 - val_loss: 0.1589\n",
      "Epoch 121/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8865 - loss: 0.2784 - val_accuracy: 0.9355 - val_loss: 0.1565\n",
      "Epoch 122/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8923 - loss: 0.2600 - val_accuracy: 0.9387 - val_loss: 0.1559\n",
      "Epoch 123/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8977 - loss: 0.2762 - val_accuracy: 0.9355 - val_loss: 0.1557\n",
      "Epoch 124/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9012 - loss: 0.2649 - val_accuracy: 0.9323 - val_loss: 0.1547\n",
      "Epoch 125/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9076 - loss: 0.2449 - val_accuracy: 0.9387 - val_loss: 0.1531\n",
      "Epoch 126/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9026 - loss: 0.2603 - val_accuracy: 0.9419 - val_loss: 0.1496\n",
      "Epoch 127/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9050 - loss: 0.2499 - val_accuracy: 0.9452 - val_loss: 0.1481\n",
      "Epoch 128/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8866 - loss: 0.2807 - val_accuracy: 0.9387 - val_loss: 0.1499\n",
      "Epoch 129/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9006 - loss: 0.2757 - val_accuracy: 0.9355 - val_loss: 0.1550\n",
      "Epoch 130/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9016 - loss: 0.2640 - val_accuracy: 0.9323 - val_loss: 0.1565\n",
      "Epoch 131/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9101 - loss: 0.2563 - val_accuracy: 0.9355 - val_loss: 0.1522\n",
      "Epoch 132/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8925 - loss: 0.2790 - val_accuracy: 0.9419 - val_loss: 0.1482\n",
      "Epoch 133/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9108 - loss: 0.2472 - val_accuracy: 0.9452 - val_loss: 0.1454\n",
      "Epoch 134/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9075 - loss: 0.2612 - val_accuracy: 0.9419 - val_loss: 0.1456\n",
      "Epoch 135/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9071 - loss: 0.2506 - val_accuracy: 0.9419 - val_loss: 0.1430\n",
      "Epoch 136/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8989 - loss: 0.2822 - val_accuracy: 0.9419 - val_loss: 0.1399\n",
      "Epoch 137/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9172 - loss: 0.2570 - val_accuracy: 0.9419 - val_loss: 0.1370\n",
      "Epoch 138/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9031 - loss: 0.2495 - val_accuracy: 0.9419 - val_loss: 0.1370\n",
      "Epoch 139/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8987 - loss: 0.2671 - val_accuracy: 0.9419 - val_loss: 0.1354\n",
      "Epoch 140/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9070 - loss: 0.2703 - val_accuracy: 0.9452 - val_loss: 0.1347\n",
      "Epoch 141/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9038 - loss: 0.2748 - val_accuracy: 0.9419 - val_loss: 0.1319\n",
      "Epoch 142/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9056 - loss: 0.2519 - val_accuracy: 0.9419 - val_loss: 0.1304\n",
      "Epoch 143/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8951 - loss: 0.2469 - val_accuracy: 0.9419 - val_loss: 0.1295\n",
      "Epoch 144/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8771 - loss: 0.2980 - val_accuracy: 0.9613 - val_loss: 0.1264\n",
      "Epoch 145/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9128 - loss: 0.2430 - val_accuracy: 0.9613 - val_loss: 0.1253\n",
      "Epoch 146/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8908 - loss: 0.2783 - val_accuracy: 0.9581 - val_loss: 0.1234\n",
      "Epoch 147/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9016 - loss: 0.2674 - val_accuracy: 0.9645 - val_loss: 0.1215\n",
      "Epoch 148/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9024 - loss: 0.2609 - val_accuracy: 0.9645 - val_loss: 0.1185\n",
      "Epoch 149/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8938 - loss: 0.2661 - val_accuracy: 0.9645 - val_loss: 0.1166\n",
      "Epoch 150/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8865 - loss: 0.2690 - val_accuracy: 0.9677 - val_loss: 0.1159\n",
      "Epoch 151/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9064 - loss: 0.2606 - val_accuracy: 0.9613 - val_loss: 0.1141\n",
      "Epoch 152/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9233 - loss: 0.2395 - val_accuracy: 0.9613 - val_loss: 0.1142\n",
      "Epoch 153/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9079 - loss: 0.2544 - val_accuracy: 0.9581 - val_loss: 0.1168\n",
      "Epoch 154/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9093 - loss: 0.2501 - val_accuracy: 0.9581 - val_loss: 0.1202\n",
      "Epoch 155/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9130 - loss: 0.2268 - val_accuracy: 0.9645 - val_loss: 0.1193\n",
      "Epoch 156/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8934 - loss: 0.2917 - val_accuracy: 0.9548 - val_loss: 0.1196\n",
      "Epoch 157/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9040 - loss: 0.2438 - val_accuracy: 0.9645 - val_loss: 0.1160\n",
      "Epoch 158/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9191 - loss: 0.2166 - val_accuracy: 0.9645 - val_loss: 0.1152\n",
      "Epoch 159/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9172 - loss: 0.2451 - val_accuracy: 0.9645 - val_loss: 0.1109\n",
      "Epoch 160/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9166 - loss: 0.2293 - val_accuracy: 0.9645 - val_loss: 0.1088\n",
      "Epoch 161/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9073 - loss: 0.2682 - val_accuracy: 0.9645 - val_loss: 0.1109\n",
      "Epoch 162/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9046 - loss: 0.2371 - val_accuracy: 0.9677 - val_loss: 0.1092\n",
      "Epoch 163/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9119 - loss: 0.2317 - val_accuracy: 0.9677 - val_loss: 0.1051\n",
      "Epoch 164/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9037 - loss: 0.2310 - val_accuracy: 0.9677 - val_loss: 0.1065\n",
      "Epoch 165/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9085 - loss: 0.2164 - val_accuracy: 0.9645 - val_loss: 0.1014\n",
      "Epoch 166/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9145 - loss: 0.2400 - val_accuracy: 0.9710 - val_loss: 0.0984\n",
      "Epoch 167/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9117 - loss: 0.2196 - val_accuracy: 0.9710 - val_loss: 0.0966\n",
      "Epoch 168/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9194 - loss: 0.2088 - val_accuracy: 0.9677 - val_loss: 0.0963\n",
      "Epoch 169/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9080 - loss: 0.2338 - val_accuracy: 0.9677 - val_loss: 0.0965\n",
      "Epoch 170/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9181 - loss: 0.2296 - val_accuracy: 0.9677 - val_loss: 0.0975\n",
      "Epoch 171/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9219 - loss: 0.2033 - val_accuracy: 0.9645 - val_loss: 0.0967\n",
      "Epoch 172/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9210 - loss: 0.2315 - val_accuracy: 0.9710 - val_loss: 0.0922\n",
      "Epoch 173/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9103 - loss: 0.2540 - val_accuracy: 0.9710 - val_loss: 0.0893\n",
      "Epoch 174/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9235 - loss: 0.2342 - val_accuracy: 0.9710 - val_loss: 0.0932\n",
      "Epoch 175/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9201 - loss: 0.2051 - val_accuracy: 0.9677 - val_loss: 0.0945\n",
      "Epoch 176/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8959 - loss: 0.2571 - val_accuracy: 0.9774 - val_loss: 0.0905\n",
      "Epoch 177/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9229 - loss: 0.2305 - val_accuracy: 0.9677 - val_loss: 0.0920\n",
      "Epoch 178/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9141 - loss: 0.2327 - val_accuracy: 0.9710 - val_loss: 0.0903\n",
      "Epoch 179/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9136 - loss: 0.2323 - val_accuracy: 0.9742 - val_loss: 0.0866\n",
      "Epoch 180/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9136 - loss: 0.2187 - val_accuracy: 0.9774 - val_loss: 0.0854\n",
      "Epoch 181/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9222 - loss: 0.2192 - val_accuracy: 0.9774 - val_loss: 0.0852\n",
      "Epoch 182/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9370 - loss: 0.2010 - val_accuracy: 0.9774 - val_loss: 0.0844\n",
      "Epoch 183/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9261 - loss: 0.2027 - val_accuracy: 0.9774 - val_loss: 0.0816\n",
      "Epoch 184/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9149 - loss: 0.2225 - val_accuracy: 0.9806 - val_loss: 0.0820\n",
      "Epoch 185/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9069 - loss: 0.2357 - val_accuracy: 0.9839 - val_loss: 0.0830\n",
      "Epoch 186/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9197 - loss: 0.2107 - val_accuracy: 0.9742 - val_loss: 0.0847\n",
      "Epoch 187/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9205 - loss: 0.2152 - val_accuracy: 0.9839 - val_loss: 0.0827\n",
      "Epoch 188/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9149 - loss: 0.2228 - val_accuracy: 0.9806 - val_loss: 0.0802\n",
      "Epoch 189/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9167 - loss: 0.2272 - val_accuracy: 0.9806 - val_loss: 0.0762\n",
      "Epoch 190/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9100 - loss: 0.2221 - val_accuracy: 0.9806 - val_loss: 0.0753\n",
      "Epoch 191/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9191 - loss: 0.2336 - val_accuracy: 0.9806 - val_loss: 0.0805\n",
      "Epoch 192/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9115 - loss: 0.2273 - val_accuracy: 0.9806 - val_loss: 0.0778\n",
      "Epoch 193/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9223 - loss: 0.2257 - val_accuracy: 0.9839 - val_loss: 0.0730\n",
      "Epoch 194/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9160 - loss: 0.2253 - val_accuracy: 0.9806 - val_loss: 0.0749\n",
      "Epoch 195/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9219 - loss: 0.2152 - val_accuracy: 0.9839 - val_loss: 0.0762\n",
      "Epoch 196/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9281 - loss: 0.2027 - val_accuracy: 0.9871 - val_loss: 0.0763\n",
      "Epoch 197/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9196 - loss: 0.2279 - val_accuracy: 0.9871 - val_loss: 0.0712\n",
      "Epoch 198/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9168 - loss: 0.2395 - val_accuracy: 0.9903 - val_loss: 0.0685\n",
      "Epoch 199/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9032 - loss: 0.2328 - val_accuracy: 0.9871 - val_loss: 0.0659\n",
      "Epoch 200/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9342 - loss: 0.1931 - val_accuracy: 0.9871 - val_loss: 0.0660\n",
      "Epoch 201/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9197 - loss: 0.2241 - val_accuracy: 0.9839 - val_loss: 0.0680\n",
      "Epoch 202/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9359 - loss: 0.1959 - val_accuracy: 0.9871 - val_loss: 0.0679\n",
      "Epoch 203/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9103 - loss: 0.2228 - val_accuracy: 0.9871 - val_loss: 0.0663\n",
      "Epoch 204/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9328 - loss: 0.1878 - val_accuracy: 0.9903 - val_loss: 0.0654\n",
      "Epoch 205/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9284 - loss: 0.1944 - val_accuracy: 0.9903 - val_loss: 0.0647\n",
      "Epoch 206/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9190 - loss: 0.2245 - val_accuracy: 0.9903 - val_loss: 0.0622\n",
      "Epoch 207/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9087 - loss: 0.2290 - val_accuracy: 0.9903 - val_loss: 0.0613\n",
      "Epoch 208/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9136 - loss: 0.2153 - val_accuracy: 0.9903 - val_loss: 0.0621\n",
      "Epoch 209/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9234 - loss: 0.1987 - val_accuracy: 0.9871 - val_loss: 0.0644\n",
      "Epoch 210/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9288 - loss: 0.2180 - val_accuracy: 0.9903 - val_loss: 0.0642\n",
      "Epoch 211/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9267 - loss: 0.1888 - val_accuracy: 0.9935 - val_loss: 0.0618\n",
      "Epoch 212/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9363 - loss: 0.1888 - val_accuracy: 0.9903 - val_loss: 0.0584\n",
      "Epoch 213/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9288 - loss: 0.2108 - val_accuracy: 0.9903 - val_loss: 0.0577\n",
      "Epoch 214/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9256 - loss: 0.2031 - val_accuracy: 0.9903 - val_loss: 0.0589\n",
      "Epoch 215/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9272 - loss: 0.2087 - val_accuracy: 0.9871 - val_loss: 0.0589\n",
      "Epoch 216/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9226 - loss: 0.2193 - val_accuracy: 0.9903 - val_loss: 0.0602\n",
      "Epoch 217/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9304 - loss: 0.2081 - val_accuracy: 0.9903 - val_loss: 0.0613\n",
      "Epoch 218/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9247 - loss: 0.1969 - val_accuracy: 0.9903 - val_loss: 0.0601\n",
      "Epoch 219/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9002 - loss: 0.2472 - val_accuracy: 0.9935 - val_loss: 0.0563\n",
      "Epoch 220/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9359 - loss: 0.1939 - val_accuracy: 0.9903 - val_loss: 0.0526\n",
      "Epoch 221/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9325 - loss: 0.2068 - val_accuracy: 0.9935 - val_loss: 0.0517\n",
      "Epoch 222/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9235 - loss: 0.2109 - val_accuracy: 0.9935 - val_loss: 0.0522\n",
      "Epoch 223/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9186 - loss: 0.2182 - val_accuracy: 0.9903 - val_loss: 0.0517\n",
      "Epoch 224/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9414 - loss: 0.1888 - val_accuracy: 0.9935 - val_loss: 0.0507\n",
      "Epoch 225/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9334 - loss: 0.1986 - val_accuracy: 0.9935 - val_loss: 0.0505\n",
      "Epoch 226/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9275 - loss: 0.1901 - val_accuracy: 0.9935 - val_loss: 0.0495\n",
      "Epoch 227/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9079 - loss: 0.2093 - val_accuracy: 0.9935 - val_loss: 0.0515\n",
      "Epoch 228/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9302 - loss: 0.1861 - val_accuracy: 0.9968 - val_loss: 0.0481\n",
      "Epoch 229/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9125 - loss: 0.2234 - val_accuracy: 0.9968 - val_loss: 0.0482\n",
      "Epoch 230/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9354 - loss: 0.1782 - val_accuracy: 0.9935 - val_loss: 0.0489\n",
      "Epoch 231/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9127 - loss: 0.2489 - val_accuracy: 0.9935 - val_loss: 0.0509\n",
      "Epoch 232/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9443 - loss: 0.1748 - val_accuracy: 0.9935 - val_loss: 0.0524\n",
      "Epoch 233/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9425 - loss: 0.1902 - val_accuracy: 0.9935 - val_loss: 0.0509\n",
      "Epoch 234/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9287 - loss: 0.1780 - val_accuracy: 0.9968 - val_loss: 0.0481\n",
      "Epoch 235/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9203 - loss: 0.1956 - val_accuracy: 0.9968 - val_loss: 0.0465\n",
      "Epoch 236/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9344 - loss: 0.1678 - val_accuracy: 0.9935 - val_loss: 0.0461\n",
      "Epoch 237/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9246 - loss: 0.1885 - val_accuracy: 0.9968 - val_loss: 0.0452\n",
      "Epoch 238/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9376 - loss: 0.1674 - val_accuracy: 0.9968 - val_loss: 0.0438\n",
      "Epoch 239/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9331 - loss: 0.2047 - val_accuracy: 0.9968 - val_loss: 0.0437\n",
      "Epoch 240/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9334 - loss: 0.1899 - val_accuracy: 0.9968 - val_loss: 0.0464\n",
      "Epoch 241/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9292 - loss: 0.1881 - val_accuracy: 0.9968 - val_loss: 0.0458\n",
      "Epoch 242/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9240 - loss: 0.2001 - val_accuracy: 0.9968 - val_loss: 0.0426\n",
      "Epoch 243/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9210 - loss: 0.1980 - val_accuracy: 0.9968 - val_loss: 0.0428\n",
      "Epoch 244/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9244 - loss: 0.1891 - val_accuracy: 0.9968 - val_loss: 0.0446\n",
      "Epoch 245/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9237 - loss: 0.2050 - val_accuracy: 0.9968 - val_loss: 0.0456\n",
      "Epoch 246/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9201 - loss: 0.2108 - val_accuracy: 0.9935 - val_loss: 0.0468\n",
      "Epoch 247/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9384 - loss: 0.1824 - val_accuracy: 0.9968 - val_loss: 0.0452\n",
      "Epoch 248/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9230 - loss: 0.2211 - val_accuracy: 0.9968 - val_loss: 0.0444\n",
      "Epoch 249/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9246 - loss: 0.2251 - val_accuracy: 0.9968 - val_loss: 0.0435\n",
      "Epoch 250/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9284 - loss: 0.1782 - val_accuracy: 0.9968 - val_loss: 0.0426\n",
      "Epoch 251/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9322 - loss: 0.1796 - val_accuracy: 0.9968 - val_loss: 0.0413\n",
      "Epoch 252/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9356 - loss: 0.1769 - val_accuracy: 0.9968 - val_loss: 0.0406\n",
      "Epoch 253/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9370 - loss: 0.1801 - val_accuracy: 0.9968 - val_loss: 0.0409\n",
      "Epoch 254/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9213 - loss: 0.2043 - val_accuracy: 0.9968 - val_loss: 0.0414\n",
      "Epoch 255/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9386 - loss: 0.1667 - val_accuracy: 0.9968 - val_loss: 0.0408\n",
      "Epoch 256/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9265 - loss: 0.1820 - val_accuracy: 0.9968 - val_loss: 0.0410\n",
      "Epoch 257/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9260 - loss: 0.1987 - val_accuracy: 0.9968 - val_loss: 0.0414\n",
      "Epoch 258/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9377 - loss: 0.1695 - val_accuracy: 0.9968 - val_loss: 0.0402\n",
      "Epoch 259/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9276 - loss: 0.2014 - val_accuracy: 0.9968 - val_loss: 0.0403\n",
      "Epoch 260/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9377 - loss: 0.1911 - val_accuracy: 0.9968 - val_loss: 0.0381\n",
      "Epoch 261/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9217 - loss: 0.1937 - val_accuracy: 0.9968 - val_loss: 0.0376\n",
      "Epoch 262/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9262 - loss: 0.2152 - val_accuracy: 0.9968 - val_loss: 0.0404\n",
      "Epoch 263/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9383 - loss: 0.1699 - val_accuracy: 0.9968 - val_loss: 0.0417\n",
      "Epoch 264/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9314 - loss: 0.1896 - val_accuracy: 0.9968 - val_loss: 0.0407\n",
      "Epoch 265/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9122 - loss: 0.2173 - val_accuracy: 0.9968 - val_loss: 0.0412\n",
      "Epoch 266/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9407 - loss: 0.1840 - val_accuracy: 0.9968 - val_loss: 0.0410\n",
      "Epoch 267/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9458 - loss: 0.1608 - val_accuracy: 0.9968 - val_loss: 0.0417\n",
      "Epoch 268/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9428 - loss: 0.1692 - val_accuracy: 0.9968 - val_loss: 0.0400\n",
      "Epoch 269/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9303 - loss: 0.1939 - val_accuracy: 0.9968 - val_loss: 0.0385\n",
      "Epoch 270/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9358 - loss: 0.1697 - val_accuracy: 0.9968 - val_loss: 0.0383\n",
      "Epoch 271/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9535 - loss: 0.1467 - val_accuracy: 0.9968 - val_loss: 0.0383\n",
      "Epoch 272/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9526 - loss: 0.1442 - val_accuracy: 0.9968 - val_loss: 0.0350\n",
      "Epoch 273/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9298 - loss: 0.1784 - val_accuracy: 0.9968 - val_loss: 0.0339\n",
      "Epoch 274/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9369 - loss: 0.1654 - val_accuracy: 0.9968 - val_loss: 0.0349\n",
      "Epoch 275/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9329 - loss: 0.1914 - val_accuracy: 0.9968 - val_loss: 0.0371\n",
      "Epoch 276/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9368 - loss: 0.1777 - val_accuracy: 0.9968 - val_loss: 0.0381\n",
      "Epoch 277/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9434 - loss: 0.1552 - val_accuracy: 0.9968 - val_loss: 0.0370\n",
      "Epoch 278/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9361 - loss: 0.1949 - val_accuracy: 0.9968 - val_loss: 0.0356\n",
      "Epoch 279/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9324 - loss: 0.1863 - val_accuracy: 0.9968 - val_loss: 0.0370\n",
      "Epoch 280/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9340 - loss: 0.1829 - val_accuracy: 0.9968 - val_loss: 0.0379\n",
      "Epoch 281/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9386 - loss: 0.1630 - val_accuracy: 0.9968 - val_loss: 0.0381\n",
      "Epoch 282/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9443 - loss: 0.1597 - val_accuracy: 0.9968 - val_loss: 0.0367\n",
      "Epoch 283/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9209 - loss: 0.1981 - val_accuracy: 0.9968 - val_loss: 0.0355\n",
      "Epoch 284/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9375 - loss: 0.1728 - val_accuracy: 0.9968 - val_loss: 0.0347\n",
      "Epoch 285/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9600 - loss: 0.1482 - val_accuracy: 0.9968 - val_loss: 0.0333\n",
      "Epoch 286/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9437 - loss: 0.1668 - val_accuracy: 0.9968 - val_loss: 0.0332\n",
      "Epoch 287/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9308 - loss: 0.2033 - val_accuracy: 0.9968 - val_loss: 0.0339\n",
      "Epoch 288/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9360 - loss: 0.1735 - val_accuracy: 0.9968 - val_loss: 0.0331\n",
      "Epoch 289/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9536 - loss: 0.1408 - val_accuracy: 0.9968 - val_loss: 0.0327\n",
      "Epoch 290/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9413 - loss: 0.1683 - val_accuracy: 0.9968 - val_loss: 0.0345\n",
      "Epoch 291/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9356 - loss: 0.1756 - val_accuracy: 0.9968 - val_loss: 0.0365\n",
      "Epoch 292/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9454 - loss: 0.1620 - val_accuracy: 0.9968 - val_loss: 0.0328\n",
      "Epoch 293/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9282 - loss: 0.2097 - val_accuracy: 1.0000 - val_loss: 0.0320\n",
      "Epoch 294/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9404 - loss: 0.1714 - val_accuracy: 1.0000 - val_loss: 0.0314\n",
      "Epoch 295/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9515 - loss: 0.1665 - val_accuracy: 0.9968 - val_loss: 0.0303\n",
      "Epoch 296/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9266 - loss: 0.2022 - val_accuracy: 0.9968 - val_loss: 0.0304\n",
      "Epoch 297/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9400 - loss: 0.1909 - val_accuracy: 0.9968 - val_loss: 0.0305\n",
      "Epoch 298/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9395 - loss: 0.1469 - val_accuracy: 0.9968 - val_loss: 0.0308\n",
      "Epoch 299/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9458 - loss: 0.1615 - val_accuracy: 1.0000 - val_loss: 0.0305\n",
      "Epoch 300/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9420 - loss: 0.1516 - val_accuracy: 1.0000 - val_loss: 0.0296\n",
      "Epoch 301/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9361 - loss: 0.1747 - val_accuracy: 1.0000 - val_loss: 0.0289\n",
      "Epoch 302/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9279 - loss: 0.1960 - val_accuracy: 1.0000 - val_loss: 0.0281\n",
      "Epoch 303/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9388 - loss: 0.1724 - val_accuracy: 1.0000 - val_loss: 0.0283\n",
      "Epoch 304/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9321 - loss: 0.1941 - val_accuracy: 0.9968 - val_loss: 0.0294\n",
      "Epoch 305/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9251 - loss: 0.1578 - val_accuracy: 0.9968 - val_loss: 0.0301\n",
      "Epoch 306/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9272 - loss: 0.1932 - val_accuracy: 1.0000 - val_loss: 0.0318\n",
      "Epoch 307/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9378 - loss: 0.1718 - val_accuracy: 1.0000 - val_loss: 0.0316\n",
      "Epoch 308/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9391 - loss: 0.1830 - val_accuracy: 1.0000 - val_loss: 0.0316\n",
      "Epoch 309/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9389 - loss: 0.1606 - val_accuracy: 1.0000 - val_loss: 0.0316\n",
      "Epoch 310/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9230 - loss: 0.1837 - val_accuracy: 1.0000 - val_loss: 0.0318\n",
      "Epoch 311/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9444 - loss: 0.1599 - val_accuracy: 1.0000 - val_loss: 0.0319\n",
      "Epoch 312/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9327 - loss: 0.1871 - val_accuracy: 1.0000 - val_loss: 0.0312\n",
      "Epoch 313/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9407 - loss: 0.1450 - val_accuracy: 1.0000 - val_loss: 0.0304\n",
      "Epoch 314/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9343 - loss: 0.1583 - val_accuracy: 0.9968 - val_loss: 0.0322\n",
      "Epoch 315/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9624 - loss: 0.1206 - val_accuracy: 0.9968 - val_loss: 0.0332\n",
      "Epoch 316/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9418 - loss: 0.1514 - val_accuracy: 1.0000 - val_loss: 0.0306\n",
      "Epoch 317/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9412 - loss: 0.1721 - val_accuracy: 1.0000 - val_loss: 0.0286\n",
      "Epoch 318/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9495 - loss: 0.1501 - val_accuracy: 0.9968 - val_loss: 0.0285\n",
      "Epoch 319/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9504 - loss: 0.1472 - val_accuracy: 0.9968 - val_loss: 0.0286\n",
      "Epoch 320/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9499 - loss: 0.1582 - val_accuracy: 0.9968 - val_loss: 0.0288\n",
      "Epoch 321/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9247 - loss: 0.1947 - val_accuracy: 0.9968 - val_loss: 0.0297\n",
      "Epoch 322/1000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9336 - loss: 0.1736 - val_accuracy: 1.0000 - val_loss: 0.0301\n",
      "Epoch 322: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x202f2d25220>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[es_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0291 \n"
     ]
    }
   ],
   "source": [
    "# モデル評価\n",
    "val_loss, val_acc = model.evaluate(X_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# 保存したモデルのロード\n",
    "model = tf.keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "[0.7948164  0.1911033  0.01408039]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 推論テスト\n",
    "predict_result = model.predict(np.array([X_test[0]]))\n",
    "print(np.squeeze(predict_result))\n",
    "print(np.argmax(np.squeeze(predict_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 混同行列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        84\n",
      "           1       0.00      0.00      0.00       121\n",
      "           2       1.00      0.01      0.02       105\n",
      "\n",
      "    accuracy                           0.00       310\n",
      "   macro avg       0.33      0.00      0.01       310\n",
      "weighted avg       0.34      0.00      0.01       310\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def print_confusion_matrix(y_true, y_pred, report=True):\n",
    "    labels = sorted(list(set(y_true)))\n",
    "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    \n",
    "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
    " \n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
    "    ax.set_ylim(len(set(y_true)), 0)\n",
    "    plt.show()\n",
    "    \n",
    "    if report:\n",
    "        print('Classification Report')\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow-Lite用のモデルへ変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# 推論専用のモデルとして保存\n",
    "model.save(model_save_path, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Vishy\\AppData\\Local\\Temp\\tmpnlpv7u5r\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Vishy\\AppData\\Local\\Temp\\tmpnlpv7u5r\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\Vishy\\AppData\\Local\\Temp\\tmpnlpv7u5r'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 42), dtype=tf.float32, name='input_1')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 3), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2211683757776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2211683757008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2211687367120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2211687378448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2211687366928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2211687377488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6484"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルを変換(量子化)\n",
    "tflite_save_path = 'model/keypoint_classifier/keypoint_classifier.tflite'\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quantized_model = converter.convert()\n",
    "\n",
    "open(tflite_save_path, 'wb').write(tflite_quantized_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推論テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入出力テンソルを取得\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], np.array([X_test[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 推論実施\n",
    "interpreter.invoke()\n",
    "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7948164  0.19110326 0.01408039]\n",
      "0\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(np.squeeze(tflite_results))\n",
    "print(np.argmax(np.squeeze(tflite_results)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
